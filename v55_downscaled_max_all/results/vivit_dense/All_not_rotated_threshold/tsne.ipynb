{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from dataset import Dataset\n",
    "from initialize import initialize_model, load_config\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "  **load_config(\"./dataset.cfg\"),\n",
    "  \"datasets_dir\": \"../../../../../datasets\"\n",
    "}\n",
    "\n",
    "model_config = load_config(\"./model.cfg\")\n",
    "run_config = load_config(\"./run.cfg\")\n",
    "\n",
    "device = run_config[\"device\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Split Indexes\n",
    "train_indexes = np.load(\"./train_indexes.npy\")\n",
    "test_indexes = np.load(\"./test_indexes.npy\")\n",
    "\n",
    "print(f\"train_indexes ({len(train_indexes)}): {train_indexes}\")\n",
    "print(f\"test_indexes ({len(test_indexes)}): {test_indexes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = \"last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = train_indexes\n",
    "# indexes = test_indexes\n",
    "\n",
    "dataset = Dataset(dataset_config, indexes = indexes)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.isdir(\"tsne\"):\n",
    "  os.mkdir(\"tsne\")\n",
    "\n",
    "checkpoint_path = f\"checkpoints/{EPOCH}.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "\n",
    "model = initialize_model(model_config[\"name\"])\n",
    "print(model)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming you have a dataset named 'dataset' and a trained model named 'model'\n",
    "# Step 1: Extract latent space representations\n",
    "latent_space = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for index, (video, target) in enumerate(dataloader):\n",
    "    video = video.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    output = model(video)\n",
    "\n",
    "    if model in [\"vae\", \"unet_vae\"]:\n",
    "        output = output[0].detach().cpu()\n",
    "    else: \n",
    "        output = output.detach().cpu()\n",
    "\n",
    "    output = F.normalize(output, p=2, dim=-1)\n",
    "\n",
    "    latent_space.append(output.numpy())  # Assuming outputs are numpy arrays\n",
    "    labels.append(indexes[index])  # Assuming targets are numpy arrays\n",
    "\n",
    "latent_space = np.concatenate(latent_space, axis=0)\n",
    "latent_space = latent_space.reshape(latent_space.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Reduce dimensionality with t-SNE\n",
    "tsne = TSNE(n_components=2, perplexity=1, random_state=42)\n",
    "latent_space_tsne = tsne.fit_transform(latent_space)\n",
    "\n",
    "# Step 3: Plot the reduced latent space\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(latent_space_tsne[:, 0], latent_space_tsne[:, 1], c=labels, cmap='viridis')\n",
    "plt.colorbar(label='Class')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title(f\"t-SNE Plot of Latent Space (Epoch: {EPOCH})\")\n",
    "plt.savefig(f\"tsne/{EPOCH}.png\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
