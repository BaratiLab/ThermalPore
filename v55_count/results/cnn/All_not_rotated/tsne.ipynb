{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TSNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.cm as cm\n",
    "import numpy as np\n",
    "import os\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "\n",
    "from dataset import Dataset\n",
    "from initialize import initialize_model, load_config\n",
    "from sklearn.manifold import TSNE\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_config = {\n",
    "  **load_config(\"./dataset.cfg\"),\n",
    "  \"datasets_dir\": \"../../../../../datasets\"\n",
    "}\n",
    "\n",
    "model_config = load_config(\"./model.cfg\")\n",
    "run_config = load_config(\"./run.cfg\")\n",
    "\n",
    "device = run_config[\"device\"] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_indexes (240): [ 50 102 134 284  25 252 144 151 242 307 314 198 154 156 177 142 277 231\n",
      " 207 170  60  79 303 108 173  11 165 220  26 300  56 201 129 114  21 248\n",
      " 183 163 155 136 159 306 210 313 227 203 181 226 244  54 193 239 276 219\n",
      "  86  92 130 294 115 139   6 229 111  18 302 272 194  40 288 119  97  43\n",
      " 271 281  15  51 234 150 103  87  57   9 153 285  59 208 254 310   7 172\n",
      " 120 240 215 317  46  36 152  76 141 237 273  75  38 184  70 143 223 269\n",
      "  24  71 291  81 316 216 305  89 233   2 132  10 283  96 218 297 164 188\n",
      "  14 225 182  49 189 169 251 309 301 308 171 105  72 257  64  67  90 250\n",
      " 304  78 241 200  33 311 298 299 256  69 107  39 287  13 191 258   1   4\n",
      " 179  82 185 279 162  31  91  27 278  28 228  41  45 262  93 268 167 101\n",
      "  65  30 270  98 202 217 124 161 280 290 249 180  66 247 158  37 116 212\n",
      " 140  16  95 168 253 135  42 109 121 260 197 224 123  61 236 106  63 125\n",
      "  20 264 266 205 222 199 261  53 209 118 127 149  88 157  62 186 131  84\n",
      "   8 122 295  19 204  44]\n",
      "test_indexes (78): [221 147 214 312  99 117  68 128 286 267 175  12  35 104 160 178 246 195\n",
      " 112  83 100 238 255 245  23  58 138   5 211   0 113 145  73 190 263  22\n",
      " 265  17 230  47  32   3 174  77 148 315 213  48  55  94 206 110  34 282\n",
      " 137  80 274 126  52 293 196 292 243 166 146 275 296  85 259 133  74 289\n",
      "  29 187 192 235 232 176]\n"
     ]
    }
   ],
   "source": [
    "# Load Split Indexes\n",
    "train_indexes = np.load(\"./train_indexes.npy\")\n",
    "test_indexes = np.load(\"./test_indexes.npy\")\n",
    "\n",
    "print(f\"train_indexes ({len(train_indexes)}): {train_indexes}\")\n",
    "print(f\"test_indexes ({len(test_indexes)}): {test_indexes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCH = \"last\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes = train_indexes\n",
    "# indexes = test_indexes\n",
    "\n",
    "dataset = Dataset(dataset_config, indexes = indexes)\n",
    "dataloader = DataLoader(dataset, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model(\n",
      "  (conv1): Conv3d(200, 100, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv1_bn): BatchNorm3d(100, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv2): Conv3d(100, 50, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv2_bn): BatchNorm3d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv3): Conv3d(50, 25, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv3_bn): BatchNorm3d(25, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (conv4): Conv3d(25, 12, kernel_size=(3, 3, 3), stride=(1, 1, 1), padding=(1, 1, 1))\n",
      "  (conv4_bn): BatchNorm3d(12, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  (fc1): Linear(in_features=49152, out_features=6144, bias=True)\n",
      "  (fc2): Linear(in_features=6144, out_features=1, bias=True)\n",
      "  (max_pool): MaxPool3d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (relu): ReLU()\n",
      ")\n",
      "(240,)\n"
     ]
    }
   ],
   "source": [
    "if not os.path.isdir(\"tsne\"):\n",
    "  os.mkdir(\"tsne\")\n",
    "\n",
    "checkpoint_path = f\"checkpoints/{EPOCH}.pth\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=torch.device(device))\n",
    "\n",
    "model = initialize_model(model_config[\"name\"])\n",
    "print(model)\n",
    "model.load_state_dict(checkpoint[\"model_state_dict\"])\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Assuming you have a dataset named 'dataset' and a trained model named 'model'\n",
    "# Step 1: Extract latent space representations\n",
    "latent_space = []\n",
    "labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "  for index, (video, target) in enumerate(dataloader):\n",
    "    video = video.to(device)\n",
    "    target = target.to(device)\n",
    "\n",
    "    output = model(video)\n",
    "\n",
    "    if model in [\"vae\", \"unet_vae\"]:\n",
    "        output = output[0].detach().cpu()\n",
    "    else: \n",
    "        output = output.detach().cpu()\n",
    "\n",
    "    output = F.normalize(output, p=2, dim=-1)\n",
    "\n",
    "    latent_space.append(output.numpy())  # Assuming outputs are numpy arrays\n",
    "    labels.append(indexes[index])  # Assuming targets are numpy arrays\n",
    "\n",
    "latent_space = np.concatenate(latent_space, axis=0)\n",
    "print(latent_space.shape)\n",
    "# latent_space = latent_space.reshape(latent_space.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240, 1)\n"
     ]
    }
   ],
   "source": [
    "latent_space = latent_space.reshape(latent_space.shape[0], -1)\n",
    "print(latent_space.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Step 2: Reduce dimensionality with t-SNE\n",
    "tsne = TSNE(n_components=1, perplexity=1, random_state=42)\n",
    "latent_space_tsne = tsne.fit_transform(latent_space)\n",
    "\n",
    "# Step 3: Plot the reduced latent space\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# Create a plot\n",
    "BUILD_LAYERS = 159\n",
    "dataset_index = [divmod(layer_index, 159)[0] for layer_index in test_indexes]\n",
    "dataset_markers = np.array([\"o\" if index == 0 else \"s\" for index in dataset_index])\n",
    "colored_layers = np.array([divmod(layer_index, 159)[1] for layer_index in test_indexes])\n",
    "cmap = cm.get_cmap(\"viridis\")\n",
    "# plt.scatter(targets, predictions, c=colored_layers, cmap=cmap, marker=dataset_markers)\n",
    "\n",
    "unique_markers = np.unique(dataset_markers)  # or yo can use: np.unique(m)\n",
    "\n",
    "x = latent_space_tsne[:, 0].flatten()\n",
    "y = latent_space_tsne[:, 1].flatten()\n",
    "\n",
    "for marker in [\"o\", \"s\"]:\n",
    "    mask = dataset_markers == marker\n",
    "    # mask is now an array of booleans that can be used for indexing\n",
    "    label = \"Velocity\"\n",
    "    if (marker == \"o\"):\n",
    "        label = \"Spacing\"\n",
    "    plt.scatter(x[mask], y[mask], marker=marker, c=colored_layers[mask], cmap=cmap, label=label)\n",
    "plt.colorbar(label='Class')\n",
    "plt.xlabel('t-SNE Dimension 1')\n",
    "plt.ylabel('t-SNE Dimension 2')\n",
    "plt.title(f\"t-SNE Plot of Latent Space (Epoch: {EPOCH})\")\n",
    "plt.savefig(f\"tsne/{EPOCH}.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
